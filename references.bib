@article{Kulkarni2023,
  author = {R. Kulkarni and M. Takalikar and N. Awatade and A. Bhalgat},
  title = {DL Based Speech to Text Converter for Audio Visual Applications},
  journal = {2023 IEEE International Conference on ICT in Business Industry \& Government (ICTBIG)},
  year = {2023},
  pages = {1-4},
  doi = {10.1109/ICTBIG59752.2023.10456000}
}

@article{Rybach2009,
  author = {David Rybach and Christian Gollan and Ralf Schlüter and Hermann Ney},
  title = {Audio segmentation for speech recognition using segment features},
  journal = {Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
  year = {2009},
  pages = {4197-4200},
  doi = {10.1109/ICASSP.2009.4960554}
}

@article{Andreyev2025,
  author = {A. Andreyev},
  title = {Quantization for OpenAI's Whisper Models: A Comparative Analysis},
  journal = {arXiv preprint arXiv:2503.09905},
  year = {2025}
}

@misc{OpenAI2022,
  author = {OpenAI},
  title = {Whisper},
  year = {2022},
  note = {Available: https://openai.com/index/whisper/},
  howpublished = {\url{https://openai.com/index/whisper/}},
  month = {Sep},
  year = {2022}
}

@inproceedings{McAuliffe2017,
  author = {M. McAuliffe and M. Socolof and S. Mihuc and M. Wagner and M. Sonderegger},
  title = {Montreal forced aligner: Trainable text-speech alignment using Kaldi},
  booktitle = {Proceedings of Interspeech},
  year = {2017},
  pages = {498-502}
}

@misc{Greenleaf2001,
  author = {Greenleaf2001},
  title = {SOFA-Modded: Singing-Oriented Forced Aligner},
  year = {n.d.},
  howpublished = {\url{https://github.com/Greenleaf2001/SOFA-Modded}},
  note = {Retrieved April 8, 2025}
}

@misc{spicytigermeat,
  author = {spicytigermeat},
  title = {LabelMakr: A GUI Toolkit for SVS Label Generation},
  year = {n.d.},
  howpublished = {\url{https://github.com/spicytigermeat/LabelMakr}},
}

@misc{openvpi,
  author = {openvpi},
  title = {Release SlurCutter 0.0.1.2 for MIDI refinement},
  year = {n.d.},
  howpublished = {\url{https://github.com/openvpi/SlurCutter}},
}

@article{Morrison2024,
  author = {M. Morrison and C. Churchwell and N. Pruyne and B. Pardo},
  title = {Fine-grained and interpretable neural speech editing},
  journal = {arXiv preprint arXiv:2407.05471},
  year = {2024}
}

@misc{nnsvsdbconverter,
  author = {UtaUtaUtau},
  title = {nnsvs-db-converter},
  year = {2025},
  howpublished = {\url{https://github.com/UtaUtaUtau/nnsvs-db-converter}},
  note = {Accessed: 2025-04-08}
}

@misc{ji2020comprehensivesurveydeepmusic,
  title         = {A Comprehensive Survey on Deep Music Generation: Multi-level Representations, Algorithms, Evaluations, and Future Directions},
  author        = {Shulei Ji and Jing Luo and Xinyu Yang},
  year          = {2020},
  eprint        = {2011.06801},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SD},
  url           = {https://arxiv.org/abs/2011.06801}
}

@article{Sisman2020,
	author = {Berrak Sisman and Junichi Yamagishi and Simon King and Haizhou Li},
	title = {An Overview of Voice Conversion and Its Challenges: From Statistical Modeling to Deep Learning
	},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	year = {2020},
	doi = {10.1109/TASLP.2020.3038524}
}

@misc{MediumSVC2023,
	author = {Medium},
	title = {State-of-the-art Singing Voice Conversion methods},
	year = {2023},
	howpublished = {\url{https://medium.com/qosmo-lab/state-of-the-art-singing-voice-conversion-methods-12f01b35405b}},
	note = {Accessed: 2025-04-08}
}

@article{Cho2021,
	author = {Yin-Ping Cho and Fu-Rong Yang and Yung-Chuan Chang and Ching-Ting Cheng and Xiao-Han Wang and Yi-Wen Liu},
	title = {A Survey on Recent Deep Learning-driven Singing Voice Synthesis Systems},
	journal = { 2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},
	year = {2021},
	doi = {10.1109/AIVR52153.2021.00067}
}

@article{Casanova2021,
	author = {Edresson Casanova and Julian Weber and Christopher Shulby and Arnaldo Candido Junior and Eren Gölge and Moacir Antonelli Ponti},
	title = {YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone},
	journal = {arXiv:2112.02418},
	year = {2021}
}

@article{Ren2020,
	author = {Yi Ren and Xu Tan and Tao Qin and Jian Luan and Zhou Zhao and Tie-Yan Liu},
	title = {DeepSinger: Singing Voice Synthesis with Data Mined From the Web},
	journal = {arXiv:2007.04590},
	year = {2020}
}

@article{Zhang2024,
	author = {Zhang, Y. and Huang, R. and Li, R. and He, J. and Xia, Y. and Chen, F. and Duan, X. and Huai, B. and Zhao, Z.},
	title = {StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence, 38},
	year = {2024},
	doi = {https://doi.org/10.1609/aaai.v38i17.29932}
}

@article{DiffSinger2021,
	author = {Jinglin Liu and Chengxi Li and Yi Ren and Feiyang Chen and Zhou Zhao},
	title = {DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism},
	journal = {arXiv:2105.02446},
	year = {2021},
	doi = {https://doi.org/10.48550/arXiv.2105.02446}
}

@article{Slizovskaia2022,
	author = {Olga Slizovskaia and Jordi Janer and Pritish Chandna and Oscar Mayor},
	title = {Voice conversion with limited data and limitless data augmentations},
	journal = {arXiv:2212.13581},
	year = {2022},
	doi = {https://doi.org/10.48550/arXiv.2212.13581}
}

@article{Guo2022,
	author = {Shuai Guo and Jiatong Shi and Tao Qian and Shinji Watanabe and Qin Jin},
	title = {SingAug: Data Augmentation for Singing Voice Synthesis with Cycle-consistent Training Strategy},
	journal = {arXiv:2203.17001},
	year = {2022},
	doi = {https://doi.org/10.48550/arXiv.2203.17001}
}

@article{Zhang2022,
	author = {Zewang Zhang and Yibin Zheng and Xinhui Li and Li Lu},
	title = {WeSinger: Data-augmented Singing Voice Synthesis with Auxiliary Losses},
	journal = {arXiv:2203.10750},
	year = {2022},
	doi = {https://doi.org/10.48550/arXiv.2203.10750}
}

@misc{openvpi-diffsinger,
	author = {openvpi},
	title = {DiffSinger},
	year = {n.d.},
	howpublished = {\url{https://github.com/openvpi/DiffSinger}},
	note = {Accessed: 2025-04-08}
}

@misc{moon-diffsinger,
	author = {MoonInTheRiver},
	title = {DiffSinger},
	year = {2022},
	howpublished = {\url{https://github.com/MoonInTheRiver/DiffSinger}},
	note = {Accessed: 2025-04-08}
}

@misc{lst-wiki,
	author = {n.a.},
	title = {LST-Wiki},
	year = {n.d.},
	howpublished = {\url{https://wiki2.coli.uni-saarland.de}},
	note = {Accessed: 2025-04-08}
}

@article{Zhou2024,
	author = {Wangjin Zhou and Zhengdong Yang and Chenhui Chu and Sheng Li and Raj Dabre and Yi Zhao and Tatsuya Kawahara},
	title = {MOS-FAD: Improving Fake Audio Detection Via Automatic Mean Opinion Score Prediction},
	journal = {arXiv:2401.13249},
	year = {2024},
	doi = {https://doi.org/10.48550/arXiv.2401.13249}
}

@article{Tang2024,
	author = {Yuxun Tang and Jiatong Shi and Yuning Wu and Qin Jin},
	title = {SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction},
	journal = {arXiv:2406.10911},
	year = {2024},
	doi = {https://doi.org/10.48550/arXiv.2406.10911}
}

@misc{mel-spectrogram,
	author = {UJAN},
	title = {Finding Mel Spectrogram Similarity},
	year = {2023},
	howpublished = {\url{https://medium.com/@UJAN/finding-mel-spectrogram-similarity-61c0993beae2}},
	note = {Accessed: 2025-04-08}
}